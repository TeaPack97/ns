{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age and gender classification with CNN\n",
    "Tento dokument je výsledkom práce študentov Tomáša Mifkoviča a Benjamína Jozefa Šiškoviča ako návrh projektu na predmet \n",
    "Neurónové siete na FIIT STU v aka. roku 2019/2020.  \n",
    "  \n",
    "## Motivácia  \n",
    "Ako projekt sme si vybrali tému **Určenie veku na základe fotografie**. Táto téma je zaujímavá vo viacerých smeroch, \n",
    "pretože by sa dala ďalej rozvýjať, hlavne ako zabezpečenie napríklad mobilných zariadení. V našom prípade by sa skôr \n",
    "mohla použiť na rozpoznanie veku používateľa live v aplikáciach na mobilných zariadeniach alebo počítačoch.  \n",
    "  \n",
    "Taktiež, v čase keď sa na internete mnohokrát zverejňujú detské fotky, ktoré sa dajú ľahko zneužiť, alebo môžu vystaviť \n",
    "deti do nebezpečných či nepríjemných situácií. Rozpoznanie tváre by mohlo znížíť počet takýchto fotografií, keď pri \n",
    "uploade fotiek vyskočí okno s upozornením.  \n",
    "  \n",
    "Náš predmet záujmu spočíva hlavne v tom, aby sme vedeli fotky čo najpresnejšie zaradiť do vekových kategórií deti, \n",
    "mladistvý, mladý, dospelý, dôchodca. Presnejšie, budeme ich zaraďovať do vekových kategórii (0-4), (5-9), (10-17), \n",
    "(18-25), (26-39),(40-59),(60-74),(75-).\n",
    "  \n",
    "## Podobné práce  \n",
    "V dnešnom modernom svete existuje veľa rozličných riešení na daný problém. Väčšina veľkých celosvetových firiem si \n",
    "buduje vlastné softvéry alebo služby, ktoré implementujú určitú formu umelej inteligencie (presnejšie neurónovú sieť) \n",
    "na rozpoznanie tváre tzv. face recognition, ktorá sa neustále učí používaním API. Každá takáto spoločnosť si model \n",
    "buduje, trénuje a testuje sama (väčšinou bez zverejnenia svojeho know-how). Medzi takéto firmy môžme zaradiť Apple, \n",
    "Microsoft, Google, či iné. Ako najznámejší príklad na rozpoznanie tváre môžme použiť FaceID od spoločnosti Apple.\n",
    "\n",
    "**How-old.net** - webová stránka od spoločnosti Microsoft, ktorá dokáže z fotky identifikovať tvár človeka a snaží sa \n",
    "uhádnuť pohlavie a vek osoby na fotke\n",
    "\n",
    "**aws.amazon.com/rekognition** - je projekt spoločnosti Amazon, ktorý dokáže rozpoznávať z videí a fotiek rôzne objekty, \n",
    "ale predovšetkým aj tváre ľudí. Aplikácia dokáže zistiť pohlavie človeka, či sa usmieva, či je šťastný či má okuliare a pod.\n",
    "\n",
    "**https://www.learnopencv.com/age-gender-classification-using-opencv-deep-learning-c-python/?fbclid=IwAR0rxSPssBGnjFOm3WsMx3jp7hqA24hicUu4iFADi9DrNjj0qQaALCERGuU** - je open-source riešenie na tento problém. V tomto riešení používajú konvolučnú neurónovú sieť (3 konvolučné vrstvy, 2 plne prepojené vrstvy a 1 výstupnú vrstvu). Neurónová sieť odhaduje vek a pohlavie osoby na fotke. Vek odhaduje klasifikačným prístupom - čiže snaží sa odhadnúť vekovú skupinu ľudí namiesto presného veku. V takomto prípade sú výsledky presnejšie a oveľa jednoduchšie vypočítať výsledok.\n",
    "## Databázy vhodné na použitie\n",
    "Aby sme vedeli náš model čo najlepšie vytrénovať a kvalitne ho otestovať, potrebujeme veľké množstvo fotiek. Dolu \n",
    "vypísané webové linky nám poskytujú voľne dostupný zdroj fotiek osôb spolu s dodatočnými informáciami ako pohlavie či \n",
    "vek osoby na fotke.\n",
    "\n",
    "[1] **https://talhassner.github.io/home/projects/Adience/Adience-data.html** - The Open University of Israel poskytujú \n",
    "databázu nefiltrovaných snímok tvári ľudí na klasifikáciu pohlavia a veku človeka (celkovo 26 580 snímok) s 8 vekovými \n",
    "skupinami (0-2, 4-6, 8-13, 15-20, 25-32, 38-43, 48-53, 60-)\n",
    "\n",
    "[2] **https://github.com/JingchunCheng/All-Age-Faces-Dataset?fbclid=IwAR0xZCjKKWhJBbce__VZdTO4SN62hbn_45pbB-h6AgO-gDboi_d9vNjOqQY** - voľne dostupný zdroj fotiek tvári ľudí prevažne z ázie. Celkový počet je 13 322 fotiek s vekovým rozpätím od 2 do 80 rokov.\n",
    "\n",
    "[3] **https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/?fbclid=IwAR07Vw9R8yi2P_D5EiXBCfZ3CYeNo92b5Z9ZWkuHo_tnWoq_8Aw5TRvhxWQ** - voľne dostupná databáza fotiek z celého sveta, ktoré sú vhodné na trénovanie a testovanie neurónových sietí. Celkový počet je viac ako 500 000.\n",
    "\n",
    "[4] **https://susanqq.github.io/UTKFace/?fbclid=IwAR2IuscY8oJ6ubuUdKCMRgCtZ0ZQJ38VMMykgbwK7WZK3LLvszBGp26HOyY** - \n",
    "voľne dostupná databáza fotiek poskytujúca doplňujúce informácie o fotkách s celkovým počtom viac ako 20 000.\n",
    "\n",
    "## High-level solution proposal \n",
    "V čase písania návrhu sme absolvovali prednášku z predmetu o téme zisťovania hrán v obrázkoch. Túto tému si budeme \n",
    "musieť naštudovať podrobnejšie.  \n",
    "Po natrénovaní neurónovej siete na datasetoch spomenutých vyššie vyskúšame fotky  \n",
    "  \n",
    "- naše, teda presne vieme, aký vek sme na nich mali  \n",
    "- vybraté fotky z datasetov, pre overenie, či je to priamo naučené alebo nastala nejaká odchylka pomocou confusion matrix\n",
    "  \n",
    "Údaje, ktoré nám poskytne neurónová sieť porovnáme so skutočnými hodnotami a tak vypočítame odchylku hodnôt. Budeme sa \n",
    "zároveň sústrediť, v ktorom veku nastala najväčšia odchylka a zistíme, prečo sa tak stalo.\n",
    "\n",
    "# Použité databázy\n",
    "\n",
    "Ako prvotné testovacie dáta sme použili voľne dostupný dataset [2].\n",
    "Dataset obsahuje 13 322 fotiek z toho 7 381 je žien a 5 941 mužov. Vekové rozpätie je od 2 do 80 rokov. \n",
    "Dataset poskytuje aj upravené/zarovnané/otočené fotky, aby bolo lepšie vidieť do tváre. Pri testovaní, \n",
    "či je lepšie používať originály fotky alebo upravená verzia vyšli lepšie výsledky pre originály \n",
    "v porovnaní dosiahnutej presnosti. Dáta sú vo formáte XXXXXAYY.jpg, kde XXXXX je poradové číslo a ked je menšie \n",
    "ako 7 382 tak sa jedná o ženu, a keď je väčšie rovné tak je to muž. YY je vek človeka na fotke.\n",
    "\n",
    "Ako druhý dataset sme použili [4]. Dataset poskytuje 23 708 fotiek ľudí od veku 1 do 116. Dáta sú v tvare Y_X_Z.jpg, \n",
    "Y je vek človeka na fotke, X je z množiny {0, 1} hovoriac pohlavie a Z je identifikačné číslo.\n",
    "\n",
    "Ako tretí dataset sme použili [1]. Dataset obsahuje 26 580 fotiek, pričom niektoré neboli použiteľné. Dáta sú v \n",
    "tvare Y_X_Z.jpg, Y je vek človeka na fotke, X je z množiny {0, 1} hovoriac pohlavie a Z je identifikačné číslo.\n",
    "\n",
    "Celkovo teda máme dataset fotiek o veľkosti ‭54 510‬ fotiek. Tento dataset sme rozdelili na 4/5 trénovaciu jednotku (43 608)\n",
    " a 1/5 na testovaciu (10 902).\n",
    "\n",
    "Predtým ako sa fotky pošlu do siete sa musia trochu upraviť. Fotky sú upravované funkciami opencv napr. resize() \n",
    "na rovnakú veľkosť (konkrétne 64x64) a delené rgb kanály hodnotou 255, aby sa hodnoty normalizovali. \n",
    "Vytvorili sme vekové kategórie (0-4),(5-9),(10-17),(18-25),(26-39),(40-59),(60-74),(75-), ktoré reprezentujú čísla \n",
    "od 0-7 (8 kategórii).\n",
    "\n",
    "<img src=\"src/age_analysis.png\">\n",
    "\n",
    "<img src=\"src/gender_analysis.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from os.path import basename\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random as ra\n",
    "from cv2 import *\n",
    "\n",
    "MUZ = 0\n",
    "ZENA = 1\n",
    "HEIGHT = 64\n",
    "WIDTH = 64\n",
    "DIM = (HEIGHT, WIDTH)\n",
    "\n",
    "\n",
    "def prep_img(file):\n",
    "    image = imread(file)\n",
    "    image = resize(image, DIM)\n",
    "    image = image / 255.0\n",
    "    image = np.array(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def decide_age(age):\n",
    "    age = int(age)\n",
    "    if age < 5:\n",
    "        return 0\n",
    "    if age < 10:\n",
    "        return 1\n",
    "    if age < 18:\n",
    "        return 2\n",
    "    if age < 26:\n",
    "        return 3\n",
    "    if age < 40:\n",
    "        return 4\n",
    "    if age < 60:\n",
    "        return 5\n",
    "    if age < 75:\n",
    "        return 6\n",
    "    return 7\n",
    "\n",
    "\n",
    "def decide_gender(number):\n",
    "    number = int(number)\n",
    "    if number < 7381:\n",
    "        return ZENA\n",
    "    return MUZ\n",
    "\n",
    "\n",
    "def get_gender(file):\n",
    "    if file[1] == '_':\n",
    "        gender = int(file[2])\n",
    "    elif file[2] == '_':\n",
    "        gender = int(file[3])\n",
    "    else:\n",
    "        gender = int(file[4])\n",
    "    return gender\n",
    "\n",
    "\n",
    "def get_age(file):\n",
    "    if file[1] == '_':\n",
    "        age = int(file[0])\n",
    "    elif file[2] == '_':\n",
    "        age = int(file[0] + file[1])\n",
    "    else:\n",
    "        age = int(file[0] + file[1] + file[2])\n",
    "    return decide_age(age=age)\n",
    "\n",
    "\n",
    "def prepare_data(images, age_labels, gender_labels):\n",
    "    train_images = []\n",
    "    train_age_labels = []\n",
    "    train_gender_labels = []\n",
    "    test_images = []\n",
    "    test_age_labels = []\n",
    "    test_gender_labels = []\n",
    "\n",
    "    pom = list(zip(images, age_labels, gender_labels))\n",
    "    ra.shuffle(pom)\n",
    "    images, age_labels, gender_labels = zip(*pom)\n",
    "\n",
    "    for x in tqdm(range(len(images))):\n",
    "        if x < int(len(images) * 4 / 5):\n",
    "            train_images.append(images[x])\n",
    "            train_age_labels.append(age_labels[x])\n",
    "            train_gender_labels.append(gender_labels[x])\n",
    "        else:\n",
    "            test_images.append(images[x])\n",
    "            test_age_labels.append(age_labels[x])\n",
    "            test_gender_labels.append(gender_labels[x])\n",
    "\n",
    "    train_images = np.array(train_images)\n",
    "    train_age_labels = np.array(train_age_labels)\n",
    "    train_gender_labels = np.array(train_gender_labels)\n",
    "    test_images = np.array(test_images)\n",
    "    test_age_labels = np.array(test_age_labels)\n",
    "    test_gender_labels = np.array(test_gender_labels)\n",
    "\n",
    "    return train_images, train_age_labels, train_gender_labels, test_images, test_age_labels, test_gender_labels\n",
    "\n",
    "\n",
    "def process_dataset3():\n",
    "    images = []\n",
    "    age_labels = []\n",
    "    gender_labels = []\n",
    "\n",
    "    for file in tqdm(glob.glob(\"..\\\\photos\\\\dataset3\\\\*.jpg\")[:50]):\n",
    "        filename = basename(file)\n",
    "        images.append(prep_img(file=file))\n",
    "        age_labels.append(get_age(file=filename))\n",
    "        gender_labels.append(get_gender(file=filename))\n",
    "\n",
    "    return images, age_labels, gender_labels\n",
    "\n",
    "\n",
    "def process_dataset2():\n",
    "    images = []\n",
    "    age_labels = []\n",
    "    gender_labels = []\n",
    "\n",
    "    for file in tqdm(glob.glob(\"..\\\\photos\\\\dataset2\\\\*.jpg\")[:50]):\n",
    "        filename = basename(file)\n",
    "        images.append(prep_img(file=file))\n",
    "        age_labels.append(get_age(file=filename))\n",
    "        gender_labels.append(get_gender(file=filename))\n",
    "\n",
    "    return images, age_labels, gender_labels\n",
    "\n",
    "\n",
    "def process_dataset1():\n",
    "    images = []\n",
    "    age_labels = []\n",
    "    gender_labels = []\n",
    "\n",
    "    for file in tqdm(glob.glob(\"..\\\\photos\\\\dataset1\\\\*.jpg\")[:50]):\n",
    "        filename = basename(file)\n",
    "        images.append(prep_img(file=file))\n",
    "        age_labels.append(decide_age(age=filename[6:8]))\n",
    "        gender_labels.append(decide_gender(number=filename[0:5]))\n",
    "\n",
    "    return images, age_labels, gender_labels\n",
    "\n",
    "\n",
    "def get_all_data():\n",
    "    print(\"Preparing dataset...\")\n",
    "    images1, age_labels1, gender_labels1 = process_dataset1()\n",
    "    images2, age_labels2, gender_labels2 = process_dataset2()\n",
    "    images3, age_labels3, gender_labels3 = process_dataset3()\n",
    "\n",
    "    images = np.concatenate((images1, images2, images3))\n",
    "    age_labels = np.concatenate((age_labels1, age_labels2, age_labels3))\n",
    "    gender_labels = np.concatenate((gender_labels1, gender_labels2, gender_labels3))\n",
    "\n",
    "    return images, age_labels, gender_labels\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    print(\"Preparing dataset...\")\n",
    "    images1, age_labels1, gender_labels1 = process_dataset1()\n",
    "    images2, age_labels2, gender_labels2 = process_dataset2()\n",
    "    images3, age_labels3, gender_labels3 = process_dataset3()\n",
    "\n",
    "    images = np.concatenate((images1, images2, images3))\n",
    "    age_labels = np.concatenate((age_labels1, age_labels2, age_labels3))\n",
    "    gender_labels = np.concatenate((gender_labels1, gender_labels2, gender_labels3))\n",
    "\n",
    "    print(\"Preparing train and test data...\")\n",
    "    return prepare_data(images, age_labels, gender_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Finálny model je zmenšená verzia modelu VGG16, ktorý je často používaný ako základ pre CNN modely. Pozostáva zo 4 skupín\n",
    "konvolučných vrstiev. Každá skupina je doplnená vrstvou BatchNormalizetion a MaxPooling vrstovou na zlepšenie trénovania.\n",
    "Prvá skupina má 32 vrchov v konvolučnej vrstve, druhá 64, tretia 128 a posledná 256. Potom sme model rozvetvili na 2 \n",
    "vetvy, pretože máme multioutput model. Každá vetva je potom ešte doplnená 2 Dense vrstvami o veľkosti 256 a Dropout\n",
    "vrstvami na zlepšenie trénovanie, aby sme trochu obmedzili overfitting modelu. Taktiež používame L2 regularizátor na\n",
    "zlepšenie trénovania a obmedzeniu pre-trénovania.\n",
    "\n",
    "<img src=\"src/model.png\">\n",
    "\n",
    "Layer (type)                    Output Shape         Param #     Connected to                     \n",
    "__________________________________________________________________________________________________\n",
    "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_1 (Conv2D)               (None, 64, 64, 32)   896         input_1[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_2 (Conv2D)               (None, 64, 64, 32)   9248        conv2d_1[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_1 (BatchNor (None, 64, 64, 32)   128         conv2d_2[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_3 (Conv2D)               (None, 32, 32, 64)   18496       max_pooling2d_1[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_4 (Conv2D)               (None, 32, 32, 64)   36928       conv2d_3[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         conv2d_4[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 64)   0           batch_normalization_2[0][0]      \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_5 (Conv2D)               (None, 16, 16, 128)  73856       max_pooling2d_2[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_6 (Conv2D)               (None, 16, 16, 128)  147584      conv2d_5[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_3 (BatchNor (None, 16, 16, 128)  512         conv2d_6[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 128)    0           batch_normalization_3[0][0]      \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_7 (Conv2D)               (None, 8, 8, 256)    295168      max_pooling2d_3[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_8 (Conv2D)               (None, 8, 8, 256)    590080      conv2d_7[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_4 (BatchNor (None, 8, 8, 256)    1024        conv2d_8[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 256)    0           batch_normalization_4[0][0]      \n",
    "__________________________________________________________________________________________________\n",
    "flatten_1 (Flatten)             (None, 4096)         0           max_pooling2d_4[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "dense_1 (Dense)                 (None, 256)          1048832     flatten_1[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "dense_3 (Dense)                 (None, 256)          1048832     flatten_1[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "dropout_3 (Dropout)             (None, 256)          0           dense_3[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "dense_2 (Dense)                 (None, 256)          65792       dropout_1[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "dense_4 (Dense)                 (None, 256)          65792       dropout_3[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "dropout_2 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "dropout_4 (Dropout)             (None, 256)          0           dense_4[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "age (Dense)                     (None, 8)            2056        dropout_2[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "gender (Dense)                  (None, 1)            257         dropout_4[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "Total params: 3,405,737\n",
    "Trainable params: 3,404,777\n",
    "Non-trainable params: 960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Input, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def create_model(height, width, pocet_vekovych_kategorii):\n",
    "    input_layer = Input(shape=(width, height, 3))\n",
    "\n",
    "    con1 = Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
    "    con11 = Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')(con1)\n",
    "    batch1 = BatchNormalization()(con11)\n",
    "    max1 = MaxPooling2D(pool_size=(2, 2))(batch1)\n",
    "\n",
    "    con2 = Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')(max1)\n",
    "    con22 = Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')(con2)\n",
    "    batch2 = BatchNormalization()(con22)\n",
    "    max2 = MaxPooling2D(pool_size=(2, 2))(batch2)\n",
    "\n",
    "    con3 = Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(max2)\n",
    "    con33 = Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(con3)\n",
    "    batch3 = BatchNormalization()(con33)\n",
    "    max3 = MaxPooling2D(pool_size=(2, 2))(batch3)\n",
    "\n",
    "    con4 = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(max3)\n",
    "    con44 = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(con4)\n",
    "    batch4 = BatchNormalization()(con44)\n",
    "    max4 = MaxPooling2D(pool_size=(2, 2))(batch4)\n",
    "\n",
    "    flat = Flatten()(max4)\n",
    "\n",
    "    # age\n",
    "    age_dense1 = Dense(units=256, kernel_regularizer=l2(l=0.005), activation='relu')(flat)\n",
    "    age_drop1 = Dropout(rate=0.5)(age_dense1)\n",
    "    age_dense2 = Dense(units=256, kernel_regularizer=l2(l=0.005), activation='relu')(age_drop1)\n",
    "    age_drop2 = Dropout(rate=0.5)(age_dense2)\n",
    "    age = Dense(units=pocet_vekovych_kategorii, activation='softmax', name=\"age\")(age_drop2)\n",
    "\n",
    "    # gender\n",
    "    gender_dense1 = Dense(units=256, kernel_regularizer=l2(0.025), activation='relu')(flat)\n",
    "    gender_drop1 = Dropout(rate=0.5)(gender_dense1)\n",
    "    gender_dense2 = Dense(units=256, kernel_regularizer=l2(0.025), activation='relu')(gender_drop1)\n",
    "    gender_drop2 = Dropout(rate=0.5)(gender_dense2)\n",
    "    gender = Dense(units=1, activation='sigmoid', name=\"gender\")(gender_drop2)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=[age, gender])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "class MyNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        super(MyNeuralNetwork, self).__init__(name='MyNeuralNetwork')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trénovanie\n",
    "\n",
    "Trénovanie pozostávalo z 30 epoch na dátach rozdelených do 64 velkých baličkov (batches). Určili sme si opitmizer Adam\n",
    "s learning ratom štandardným 0.001. Určili sme si loss funkcie pre jednotlivé output vrstvy. Pre Age sme vybrali \n",
    "sparse categorical crossentropy a pre Gender sme vybrali binary_crossentropy, keďže ide len o clasifikáciu 0 alebo 1. \n",
    "Určili sme si metriky - štandardne sme ostali pri presnosti (accuracy) jednotlivých výstupov. Prvé treningy modelu \n",
    "boli bez EarlyStoppingu, aby sme videli ako sa náš model správa počas všetkých 30 epochách. Všetky trénovania sme \n",
    "logovali prostredníctvom TensorBoardu do logovacích súborov. Trénovanie modelu prebiehalo na rozdelených dátach \n",
    "opísaných v kapitole \"Použité databázy\". Zadali sme hodnotu shuffle=True, aby sme dosiahli náhodné poradie batchov \n",
    "pre každú epochu. Po dotrénovaní sme si model s jeho parametrami uložili do súboru \"model.h5\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from datetime import datetime\n",
    "from src.model import create_model\n",
    "from keras.optimizers import Adam\n",
    "from src.import_data import *\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "\n",
    "train_images, train_age_labels, train_gender_labels, test_images, test_age_labels, test_gender_labels = get_data()\n",
    "\n",
    "model = create_model(HEIGHT, WIDTH, 8)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss={\"age\": \"sparse_categorical_crossentropy\", \"gender\": \"binary_crossentropy\"},\n",
    "    metrics={\"age\": \"accuracy\", \"gender\": \"accuracy\"}\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', mode=\"min\", verbose=1, patience=5),\n",
    "    TensorBoard(\n",
    "        log_dir=os.path.join(\"..\\\\logs\\\\\", str(datetime.now().strftime(\"%b_%d_%Y_%H_%M_%S\"))),\n",
    "        histogram_freq=1,\n",
    "        profile_batch=0)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_images,\n",
    "    y={\"age\": train_age_labels, \"gender\": train_gender_labels},\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    validation_data=(test_images, {\"age\": test_age_labels, \"gender\": test_gender_labels}),\n",
    "    callbacks=callbacks,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "model.save(\"model.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Výsledky\n",
    "Po každom jednom trénovaní sme si zobrazili pomocou knižnice matlibplot výslekdy testovania. Uložili sme si 4 obrázky, \n",
    "konkrétne presnosť veku, presnosť pohlavia, chyby vo veku a chyby v pohlaví. Výsledky sme porovnávali z predošlými \n",
    "trénovaniami, aby sme zistili, či sme správne upravovali model a či sa len nezhoršoval.\n",
    "\n",
    "### Age Accuracy\n",
    "<img src=\"src/model_age_accuracy.png\">\n",
    "\n",
    "### Age Loss\n",
    "<img src=\"src/model_age_loss.png\">\n",
    "\n",
    "### Gender Accuracy\n",
    "<img src=\"src/model_gender_accuracy.png\">\n",
    "\n",
    "### Gender Loss\n",
    "<img src=\"src/model_gender_loss.png\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['age_accuracy'])\n",
    "plt.plot(history.history['val_age_accuracy'])\n",
    "plt.title('Model Age Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('model_age_accuracy.png')\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(history.history['gender_accuracy'])\n",
    "plt.plot(history.history['val_gender_accuracy'])\n",
    "plt.title('Model Gender Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('model_gender_accuracy.png')\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(history.history['age_loss'])\n",
    "plt.plot(history.history['val_age_loss'])\n",
    "plt.title('Model Age Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('model_age_loss.png')\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(history.history['gender_loss'])\n",
    "plt.plot(history.history['val_gender_loss'])\n",
    "plt.title('Model Gender Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('model_gender_loss.png')\n",
    "plt.clf()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experimenty\n",
    "Náš model pri checkpointe vyzeral nasledovne"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layers = [\n",
    "   Conv2D(filters=16,kernel_size=7,padding='same',activation='relu'),\n",
    "   MaxPooling2D(pool_size=(2, 2)),\n",
    "   Conv2D(filters=32,kernel_size=5,padding='same',activation='relu'),\n",
    "   MaxPooling2D(pool_size=(2, 2)),\n",
    "   Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'),\n",
    "   MaxPooling2D(pool_size=(2, 2)),\n",
    "   Flatten(),\n",
    "   Dense(units=512,activation='relu'),\n",
    "   Dense(units=16,activation='softmax')]\n",
    "   "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Neobsahuje ani multioutput vrstvy a sustreďovali sme sa len na jeden výstup. To sa ukázalo ako veľmi neefektívne rišenie.\n",
    "Preto sme náš model upravili na multioutput - age, gender. Ako pri prvom checkpointe sme dosahovali príliš vysoký \n",
    "overfitting. Po konzultáciách nám bolo odporúčané pridať regularizátory + dropout vrstvy a BatchNormalization vrstvy.\n",
    "\n",
    "Celkovo sme model zmenili 10 krát, a skúšali ktorý vychádza najlepšie a kde dosahujeme najmenší overfitting. Zmeny boli\n",
    "vykonané hlavne pridaním/menením optimalizačných aelbo regularizačných parametrov. Najlepšie nám vyšiel model, ktorý je \n",
    "opísaný v kapitole \"Model\". Aj na základe výsledkov finálneho modelu máme stále problém s pretrénovaním modelu po \n",
    "približne 15 epoche. Aby sme nemuseli presne zisťovať kedy vypnuť trénovanie a manuálne zadávať počet epoch, použili sme\n",
    " EarlyStopping, ktorý sme zamerali na celkovú validačnú loss hodnotu. Hovorí sa, že ak začne stúpať loss, väčšinou to \n",
    " už lepšie nebude, a preto vtedy zastavíme trénovanie a model uložíme s natrénovanými parametrami. Všetky trénovania sú\n",
    "  zaznamenané v logovacích súboroch. Ak by sme mali ohodnotiť model na jednotlivé výstupy tak, klasifikácia pohlavia \n",
    "  dopadla veľmi dobre, na trénovacích dátach sme dosahovali výsledky 97-99% presnosť a na validačných 90-92%. Horšie\n",
    "  na tom bola časť klasifikácie veku kde sme na trénovacích dátach dosiahli presnosť viac ako 90%, ale na validačných \n",
    "  sa to bohužial zastavilo len pri 57-59% - čo je v podstate tiež slušné číslo, keďže sa to kategorizuje na 8 výstupov.\n",
    "  \n",
    "### Test modelu\n",
    "Ako test sme použili naše fotky, ktoré model vôbec nikdy nevidel. Zobrazená tebuľka ukazuje ako nás odhadol.\n",
    "\n",
    "FOTKA C:  0\n",
    "Age:  3  Gender:  0\n",
    "Predicted Age:  4  Gender:  0\n",
    "\n",
    "FOTKA C:  1\n",
    "Age:  3  Gender:  0\n",
    "Predicted Age:  4  Gender:  0\n",
    "\n",
    "Model správne odhadol naše pohlavie - 0 = 0, sme muži. Ale o 1 kategóriu zle zaradil vek. Patríme do vekovej katégorie \n",
    "3 (18-25), ale odhadol nás na vekovú kategóriu 4 (26-39). Keďže sa sekol len o jednu kategóriu nie je to až tak zlé. \n",
    "Kľudne nás mohol odhadnúť na 27 ročných mužov."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.import_data import *\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def guess():\n",
    "    images = []\n",
    "    age_labels = []\n",
    "    gender_labels = []\n",
    "\n",
    "    for file in tqdm(glob.glob(\"..\\\\photos\\\\guess\\\\*.jpg\")):\n",
    "        filename = basename(file)\n",
    "        images.append(prep_img(file=file))\n",
    "        age_labels.append(get_age(file=filename))\n",
    "        gender_labels.append(get_gender(file=filename))\n",
    "\n",
    "    images = np.array(images)\n",
    "    age_labels = np.array(age_labels)\n",
    "    gender_labels = np.array(gender_labels)\n",
    "\n",
    "    model = load_model(\"model.h5\", compile=True)\n",
    "    predict = model.predict(images)\n",
    "\n",
    "    for x in range(len(images)):\n",
    "        print(\"FOTKA C: \", x)\n",
    "        print(\"Age: \", age_labels[x], \" Gender: \", gender_labels[x])\n",
    "        print(\"Predicted Age: \", np.argmax(predict[0][x]), \" Gender: \", np.argmax(predict[1][x]))\n",
    "\n",
    "\n",
    "guess()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Záver\n",
    "V našom projekte sme vytvorili CNN s dvomi výstupnými vrstvami na určenie veku a pohlavie osoby na fotke. Trénovanie a \n",
    "úpravy modelu sme experimentálne overovali a snažili sme sa dosahovať lepších výsledkov. Celkovo sme vykonali viac ako\n",
    " 10 experimentov. Všetky trénovania sú zaznamené v logovacích súboroch. Na zníženie pretrénovania modelu sme použili \n",
    " rôzne regularizátory (l2), taktiež droput a batch-normalization vrstvy. Finálne trénovanie, ktoré bolo monitorované \n",
    " EARLY STOPPINGOM vyšlo na 12 epoch z celkových 30. Stále sme dosahovali pomerne veľkého pretrénovania pri väčších \n",
    " opakovaniach. Ako možné rozšírenia a zlepšenia vidíme v zjednodušení modelu + pridaní regularizátorov na age vetvu a \n",
    " taktiež data augmention pomocou ImageDataGeneratoru. Bohužial ImageDataGenerator sa nám nepodarilo pridať do projektu, \n",
    " aj keď sme sa o to snažili. Celkovo sme sa veľa naučili pri práci na projekte o neurónových sieťach a oboznámili s \n",
    " technikami používanými v praxi."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}