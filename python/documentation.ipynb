{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Ako prvotné testovacie dáta sme použili voľne dostupný dataset zo stránky \n",
    "https://github.com/JingchunCheng/All-Age-Faces-Dataset?fbclid=IwAR3sesRO_P9-hGeQN2xfupIsEbIuUNNH2Ul_wPLgaH32d-O6ivTsBIv567A\n",
    "\n",
    "Dataset obsahuje 13 322 fotiek z toho 7 381 je žien a 5 941 mužov. Vekové rozpätie je od 2 do 80 rokov. \n",
    "Dataset poskytuje aj upravené/zarovnané/otočené fotky, aby bolo lepšie vidieť do tváre. Pri testovaní, \n",
    "či je lepšie používať originály fotky alebo upravená verzia vyšli lepšie výsledky pre originály \n",
    "v porovnaní dosiahnutej presnosti.\n",
    "\n",
    "Dáta sú už predom rozdelené na testovacie a trénovacie presne na polovicu.Predtým ako sa fotky pošlu do siete sa \n",
    "musia trochu upraviť. Fotky sú upravované funkciami opencv napr. resize() a delené rgb kanály hodnotou 255, \n",
    "aby hodnoty boli v rozsahu 0-1. Každá fotka má iné rozlíšenie, tzn. že musíme ich pretransformovať \n",
    "na rovnaký formát pomocou funkcie resize(). Názov fotky už obsahuje potrebné informácie ako rok aj pohlavie. \n",
    "Je vo formáte XXXXXAYY.jpg, kde XXXXX je poradové číslo a ked je menšie ako 7 382 tak sa jedná o ženu, \n",
    "a keď je väčšie rovné tak je to muž. YY je vek človeka na fotke. Vytvorili sme vekové kategórie \n",
    "(0-4),(5-9),(10-17),(18-25),(26-39),(40-59),(60-74),(75-), ktoré reprezentujú čísla od 0-7 (8 kategórii).\n",
    "\n",
    "Keďže je v datasete len 13 322 fotiek a sú rozdelené na polovicu, neurónová sieť sa veľmi pomaly učila aj pri 10 epochách. \n",
    "Z toho dôvodu sme k týmto dátam pribalili druhý dataset z https://susanqq.github.io/UTKFace/?fbclid=IwAR2IuscY8oJ6ubuUdKCMRgCtZ0ZQJ38VMMykgbwK7WZK3LLvszBGp26HOyY \n",
    "Dataset poskytuje 23 708 fotiek ľudí od veku 1 do 116. V názve fotografie už máme pripravené pohlavie a vek človeka na fotke. \n",
    "Tento dataset sme rozdelili na 3/4 trénovaciu jednotku a 1/4 na testovaciu. Výsledné polia fotiek sme spojili spolu s predošlými fotkami. \n",
    "Výsledna trénovacia jednotka má veľkosť 24 418 fotiek. Pri trénovaní s 30timi epochami sme dosiahli nasledovné výsledky.\n",
    "\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param  \n",
    "\n",
    "=================================================================\n",
    "conv2d_1 (Conv2D)            (None, 75, 85, 16)        2368      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 37, 42, 16)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 37, 42, 32)        12832     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2 (None, 18, 21, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 18, 21, 64)        18496     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_3 (MaxPooling2 (None, 9, 10, 64)         0         \n",
    "_________________________________________________________________\n",
    "flatten_1 (Flatten)          (None, 5760)              0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 512)               2949632   \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 16)                8208      \n",
    "\n",
    "=================================================================\n",
    "\n",
    "Total params: 2,991,536\n",
    "\n",
    "Trainable params: 2,991,536\n",
    "\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from os.path import basename\n",
    "import numpy as np\n",
    "import random as ra\n",
    "from cv2 import *\n",
    "\n",
    "HEIGHT = 85\n",
    "WIDTH = 75\n",
    "DIM = (HEIGHT, WIDTH)\n",
    "\n",
    "\n",
    "def prep_img(image):\n",
    "    image = resize(image, DIM)\n",
    "    image = image / 255.0\n",
    "    image = np.array(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def decide_age(age):\n",
    "    if age < 5:\n",
    "        return 0\n",
    "    if age < 10:\n",
    "        return 1\n",
    "    if age < 18:\n",
    "        return 2\n",
    "    if age < 26:\n",
    "        return 3\n",
    "    if age < 40:\n",
    "        return 4\n",
    "    if age < 60:\n",
    "        return 5\n",
    "    if age < 75:\n",
    "        return 6\n",
    "    return 7\n",
    "\n",
    "\n",
    "def prep_label(age, number):\n",
    "    number = int(number)\n",
    "    age = int(age)\n",
    "    if number < 7381:\n",
    "        return decide_age(age=age)\n",
    "    return decide_age(age=age) + 8\n",
    "\n",
    "\n",
    "def get_age_gender(name):\n",
    "    name = basename(name)\n",
    "    if name[1] == '_':\n",
    "        age = int(name[0])\n",
    "        gender = int(name[2])\n",
    "    elif name[2] == '_':\n",
    "        age = int(name[0] + name[1])\n",
    "        gender = int(name[3])\n",
    "    else:\n",
    "        age = int(name[0] + name[1] + name[2])\n",
    "        gender = int(name[4])\n",
    "    if gender == 1:\n",
    "        age = decide_age(age=age)\n",
    "    else:\n",
    "        age = decide_age(age=age) + 8\n",
    "    return age\n",
    "\n",
    "\n",
    "def get_photos(file, images, labels):\n",
    "    f = open(file, \"r\")\n",
    "\n",
    "    for x in f:\n",
    "        img = imread(\"D:\\\\Nastavenia\\\\Dokumenty\\\\STU\\\\4rocnik\\\\neu\\\\ns\\\\python\\\\photos\\\\original_images\\\\\" + x[0:12])\n",
    "        images.append(prep_img(image=img))\n",
    "        labels.append(prep_label(age=x[6:8], number=x[0:5]))\n",
    "    f.close()\n",
    "    return\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    print(\"loading first dataset...\")\n",
    "    train_images1, train_labels1, test_images1, test_labels1 = get_data1()\n",
    "    print(\"loading second dataset...\")\n",
    "    train_images2, train_labels2, test_images2, test_labels2 = get_data2()\n",
    "\n",
    "    print(\"preparing dataset...\")\n",
    "    train_images = np.concatenate((train_images1, train_images2))\n",
    "    train_labels = np.concatenate((train_labels1, train_labels2))\n",
    "    test_images = np.concatenate((test_images1, test_images2))\n",
    "    test_labels = np.concatenate((test_labels1, test_labels2))\n",
    "\n",
    "    train_images = np.array(train_images)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_images = np.array(test_images)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "\n",
    "def get_data1():\n",
    "    train_labels = []\n",
    "    train_images = []\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "\n",
    "    get_photos(file=\"D:\\\\Nastavenia\\\\Dokumenty\\\\STU\\\\4rocnik\\\\neu\\\\ns\\\\python\\\\photos\\\\image_sets\\\\train.txt\",\n",
    "               images=train_images, labels=train_labels)\n",
    "    get_photos(file=\"D:\\\\Nastavenia\\\\Dokumenty\\\\STU\\\\4rocnik\\\\neu\\\\ns\\\\python\\\\photos\\\\image_sets\\\\val.txt\",\n",
    "               images=test_images, labels=test_labels)\n",
    "\n",
    "    train_images = np.array(train_images)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_images = np.array(test_images)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "\n",
    "def get_data2():\n",
    "    train_labels = []\n",
    "    train_images = []\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "\n",
    "    # DIMENSION (200,200,3)\n",
    "    images = [prep_img(imread(file)) for file in glob.glob(\"..\\\\photos\\\\mixed\\\\UTKFace\\\\*.jpg\")]\n",
    "    labels = [get_age_gender(file) for file in glob.glob(\"..\\\\photos\\\\mixed\\\\UTKFace\\\\*.jpg\")]\n",
    "\n",
    "    pom = list(zip(images, labels))\n",
    "    ra.shuffle(pom)\n",
    "    images, labels = zip(*pom)\n",
    "\n",
    "    for x in range(0, int(len(images) * 3 / 4)):\n",
    "        train_images.append(images[x])\n",
    "        train_labels.append(labels[x])\n",
    "    for x in range(int(len(images) * 3 / 4), len(images)):\n",
    "        test_images.append(images[x])\n",
    "        test_labels.append(labels[x])\n",
    "\n",
    "    train_images = np.array(train_images)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_images = np.array(test_images)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Model pozostáva z 3 konvolučných vrstiev, 3 MaxPooling vrstiev a z 2 full-mesh (Dense) vrstiev.\n",
    "Ako aktivačnú funkciu používame relu pretože sa pri testovaní ukázala ako rýchlejšia a lepšia.\n",
    "\n",
    "<img src=\"model.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten\n",
    "\n",
    "\n",
    "class MyNeuralNetwork(Sequential):\n",
    "    def __init__(self, height, width):\n",
    "        super(MyNeuralNetwork, self).__init__(name='MyNeuralNetwork')\n",
    "        self.add(\n",
    "            Conv2D(\n",
    "                input_shape=(width, height, 3),\n",
    "                filters=16,\n",
    "                kernel_size=7,\n",
    "                padding='same',\n",
    "                activation='relu')\n",
    "        )\n",
    "        self.add(\n",
    "            MaxPooling2D(pool_size=(2, 2))\n",
    "        )\n",
    "        self.add(\n",
    "            Conv2D(\n",
    "                filters=32,\n",
    "                kernel_size=5,\n",
    "                padding='same',\n",
    "                activation='relu')\n",
    "        )\n",
    "        self.add(\n",
    "            MaxPooling2D(pool_size=(2, 2))\n",
    "        )\n",
    "        self.add(\n",
    "            Conv2D(\n",
    "                filters=64,\n",
    "                kernel_size=3,\n",
    "                padding='same',\n",
    "                activation='relu')\n",
    "        )\n",
    "        self.add(\n",
    "            MaxPooling2D(pool_size=(2, 2))\n",
    "        )\n",
    "        self.add(\n",
    "            Flatten()\n",
    "        )\n",
    "        self.add(\n",
    "            Dense(\n",
    "                units=512,\n",
    "                activation='relu')\n",
    "        )\n",
    "        self.add(\n",
    "            Dense(\n",
    "                units=16,\n",
    "                activation='softmax')\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trénovanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.model import MyNeuralNetwork\n",
    "from keras.optimizers import Adam\n",
    "from src.import_data import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 30\n",
    "\n",
    "train_images, train_labels, test_images, test_labels = get_data()\n",
    "\n",
    "model = MyNeuralNetwork(HEIGHT, WIDTH)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    # TensorBoard(\n",
    "    #     log_dir=\"logs/\" + timestamp(),\n",
    "    #     histogram_freq=1,\n",
    "    #     profile_batch=0)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_images,\n",
    "    y=train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    callbacks=callbacks,\n",
    "    epochs=EPOCHS)\n",
    "\n",
    "model.save(\"model.h5\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Epoch 1/30\n",
    "\n",
    "24418/24418 - 210s 9ms/step - loss: 1.8549 - accuracy: 0.3661 - val_loss: 1.7345 - val_accuracy: 0.4010\n",
    "\n",
    "Epoch 2/30\n",
    "\n",
    "24418/24418 - 203s 8ms/step - loss: 1.4222 - accuracy: 0.4728 - val_loss: 1.5859 - val_accuracy: 0.4321\n",
    "\n",
    "Epoch 3/30\n",
    "\n",
    "24418/24418 - 201s 8ms/step - loss: 1.2259 - accuracy: 0.5303 - val_loss: 1.5896 - val_accuracy: 0.4288\n",
    "\n",
    "Epoch 4/30\n",
    "\n",
    "24418/24418 - 207s 8ms/step - loss: 1.0114 - accuracy: 0.6077 - val_loss: 1.5885 - val_accuracy: 0.4412\n",
    "\n",
    "Epoch 5/30\n",
    "\n",
    "24418/24418 - 201s 8ms/step - loss: 0.7618 - accuracy: 0.7063 - val_loss: 2.0058 - val_accuracy: 0.4224\n",
    "\n",
    "Epoch 6/30\n",
    "\n",
    "24418/24418 - 201s 8ms/step - loss: 0.5239 - accuracy: 0.8011 - val_loss: 2.2831 - val_accuracy: 0.4123\n",
    "\n",
    "Epoch 7/30\n",
    "\n",
    "24418/24418 - 205s 8ms/step - loss: 0.3575 - accuracy: 0.8690 - val_loss: 3.1012 - val_accuracy: 0.4112\n",
    "\n",
    "Epoch 8/30\n",
    "\n",
    "24418/24418 - 204s 8ms/step - loss: 0.2834 - accuracy: 0.8975 - val_loss: 3.3936 - val_accuracy: 0.3999\n",
    "\n",
    "Epoch 9/30\n",
    "\n",
    "24418/24418 - 215s 9ms/step - loss: 0.2273 - accuracy: 0.9258 - val_loss: 3.4670 - val_accuracy: 0.3957\n",
    "\n",
    "Epoch 10/30\n",
    "\n",
    "24418/24418 - 202s 8ms/step - loss: 0.2039 - accuracy: 0.9335 - val_loss: 4.1941 - val_accuracy: 0.4017\n",
    "\n",
    "Epoch 11/30\n",
    "\n",
    "24418/24418 - 202s 8ms/step - loss: 0.1730 - accuracy: 0.9465 - val_loss: 3.9829 - val_accuracy: 0.4008\n",
    "\n",
    "Epoch 12/30\n",
    "\n",
    "24418/24418 - 202s 8ms/step - loss: 0.1702 - accuracy: 0.9470 - val_loss: 4.1563 - val_accuracy: 0.4025\n",
    "\n",
    "Epoch 13/30\n",
    "\n",
    "24418/24418 - 201s 8ms/step - loss: 0.1683 - accuracy: 0.9499 - val_loss: 4.2153 - val_accuracy: 0.3943\n",
    "\n",
    "Epoch 14/30\n",
    "\n",
    "24418/24418 - 200s 8ms/step - loss: 0.1447 - accuracy: 0.9556 - val_loss: 4.3784 - val_accuracy: 0.3920\n",
    "\n",
    "Epoch 15/30\n",
    "\n",
    "24418/24418 - 201s 8ms/step - loss: 0.1433 - accuracy: 0.9568 - val_loss: 4.6707 - val_accuracy: 0.4000\n",
    "\n",
    "Epoch 16/30\n",
    "\n",
    "24418/24418 - 202s 8ms/step - loss: 0.1367 - accuracy: 0.9615 - val_loss: 4.4424 - val_accuracy: 0.4046\n",
    "\n",
    "Epoch 17/30\n",
    "\n",
    "24418/24418 - 201s 8ms/step - loss: 0.1308 - accuracy: 0.9642 - val_loss: 4.6545 - val_accuracy: 0.3982\n",
    "\n",
    "Epoch 18/30\n",
    "\n",
    "24418/24418 - 203s 8ms/step - loss: 0.1288 - accuracy: 0.9628 - val_loss: 4.7822 - val_accuracy: 0.4049\n",
    "\n",
    "Epoch 19/30\n",
    "\n",
    "24418/24418 - 200s 8ms/step - loss: 0.1237 - accuracy: 0.9632 - val_loss: 5.6877 - val_accuracy: 0.3928\n",
    "\n",
    "Epoch 20/30\n",
    "\n",
    "24418/24418 - 201s 8ms/step - loss: 0.1147 - accuracy: 0.9672 - val_loss: 5.2998 - val_accuracy: 0.3844\n",
    "\n",
    "Epoch 21/30\n",
    "\n",
    "24418/24418 - 200s 8ms/step - loss: 0.1139 - accuracy: 0.9670 - val_loss: 5.3759 - val_accuracy: 0.4026\n",
    "\n",
    "Epoch 22/30\n",
    "\n",
    "24418/24418 - 201s 8ms/step - loss: 0.1171 - accuracy: 0.9669 - val_loss: 5.0882 - val_accuracy: 0.3961\n",
    "\n",
    "Epoch 23/30\n",
    "\n",
    "24418/24418 - 202s 8ms/step - loss: 0.1047 - accuracy: 0.9676 - val_loss: 5.3367 - val_accuracy: 0.3868\n",
    "\n",
    "Epoch 24/30\n",
    "\n",
    "24418/24418 - 200s 8ms/step - loss: 0.0996 - accuracy: 0.9722 - val_loss: 5.8617 - val_accuracy: 0.4073\n",
    "\n",
    "Epoch 25/30\n",
    "\n",
    "24418/24418 - 203s 8ms/step - loss: 0.1057 - accuracy: 0.9706 - val_loss: 5.7737 - val_accuracy: 0.3915\n",
    "\n",
    "Epoch 26/30\n",
    "\n",
    "24418/24418 - 201s 8ms/step - loss: 0.1021 - accuracy: 0.9711 - val_loss: 5.3301 - val_accuracy: 0.3816\n",
    "\n",
    "Epoch 27/30\n",
    "\n",
    "24418/24418 - 201s 8ms/step - loss: 0.0963 - accuracy: 0.9715 - val_loss: 6.0866 - val_accuracy: 0.3891\n",
    "\n",
    "Epoch 28/30\n",
    "\n",
    "24418/24418 - 201s 8ms/step - loss: 0.1062 - accuracy: 0.9693 - val_loss: 5.2993 - val_accuracy: 0.3930\n",
    "\n",
    "Epoch 29/30\n",
    "\n",
    "24418/24418 - 201s 8ms/step - loss: 0.0842 - accuracy: 0.9762 - val_loss: 5.6196 - val_accuracy: 0.3877\n",
    "\n",
    "Epoch 30/30\n",
    "\n",
    "24418/24418 - 203s 8ms/step - loss: 0.0908 - accuracy: 0.9742 - val_loss: 6.4543 - val_accuracy: 0.3874"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Výsledky\n",
    "### Accuracy\n",
    "<img src=\"src/model_accuracy.png\">\n",
    "\n",
    "### Loss\n",
    "<img src=\"src/model_loss.png\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e18131f55686>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('model_accuracy.png')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('model_loss.png')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}